# -*- coding: utf-8 -*-
"""class ml project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ucHGHUSyUUsU8DCnfmfVXjyZb7Aoqoiq
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('Healthcare-Diabetes.csv')
df.head()
df["Outcome"]
df.drop("Id", axis = 1, inplace = True)
df.shape
df.isnull().sum()

#Missing values distribution
print((df == 0).sum())
print((df.drop("Outcome", axis = 1) == 0).sum().sum(), "total missing values")
df.hist(figsize = (10, 15), bins = 15)
df["Glucose"] = df["Glucose"].replace(0, np.nan)
df["BloodPressure"] = df["BloodPressure"].replace(0, np.nan)
df["SkinThickness"] = df["SkinThickness"].replace(0, np.nan)
df["Insulin"] = df["Insulin"].replace(0, np.nan)
df["BMI"] = df["BMI"].replace(0, np.nan)
df.hist(figsize = (10, 15), bins = 15)
fig, axes = plt.subplots(2,4, figsize = (12,6))

sns.boxplot(df['Pregnancies'], ax = axes[0,0])
axes[0,0].set_title('Pregnancies')

sns.boxplot(df['Glucose'], ax = axes[0,1])
axes[0,1].set_title('Glucose')

sns.boxplot(df['BloodPressure'], ax = axes[0,2])
axes[0,2].set_title('BloodPressure')

sns.boxplot(df['SkinThickness'], ax = axes[0,3])
sns.boxplot(df['Insulin'], ax = axes[1,0])
axes[1,0].set_title('Insulin')

sns.boxplot(df['BMI'], ax = axes[1,1])
axes[1,1].set_title('BMI')

sns.boxplot(df['DiabetesPedigreeFunction'], ax = axes[1,2])
axes[1,2].set_title('DiabetesPedigreeFunction')

sns.boxplot(df['Age'], ax = axes[1,3])
axes[1,3].set_title('Age')

plt.tight_layout()
X = df.drop("Outcome", axis = 1)
y = df["Outcome"]

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)

from sklearn.impute import KNNImputer

# Create a KNNImputer object
imputer = KNNImputer(missing_values=np.nan, n_neighbors=5, add_indicator = True)  # Set the desired number of neighbors

# Perform KNN imputation
imputer = imputer.fit(X_train)
X_train = pd.DataFrame(imputer.transform(X_train))
X_test = pd.DataFrame(imputer.transform(X_test))

from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit the scaler to the data and transform the data
scaled_data = scaler.fit(X_train)
X_train = pd.DataFrame(scaler.transform(X_train))
X_train.head

scaled_data = scaler.fit(X_test)
X_test = pd.DataFrame(scaler.transform(X_test))
X_test.head

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import roc_curve, auc, roc_auc_score
model = RandomForestClassifier()

# Define the grid of hyperparameters to search
param_grid = {
    'n_estimators': [20, 40, 60, 80, 100],
    'max_depth': [15, 20, 25],
    'min_samples_split': [1, 2, 3],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt'],
}

random_search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=5, scoring='accuracy', verbose = 3)
random_search.fit(X_train, y_train)

# Get the best hyperparameters and score
best_params = random_search.best_params_
best_score = random_search.best_score_

# Train a new model using the best hyperparameters
best_model = RandomForestClassifier(**best_params)
best_model.fit(X_train, y_train)

# Need feature importances
importances = best_model.feature_importances_[:8]

# Get the feature names
feature_names = X.columns.tolist()  # Replace with your actual feature names

# Sort the feature importances in descending order
sorted_indices = np.argsort(importances)[::-1]
sorted_importances = importances[sorted_indices]
sorted_feature_names = [feature_names[i] for i in sorted_indices]

# Plot the feature importances
plt.figure(figsize=(10, 6))
plt.bar(range(len(importances)), sorted_importances, tick_label=sorted_feature_names)
plt.xticks(rotation=90)
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('Feature Importance')
plt.show()

# Evaluate the best model on the test data
accuracy = best_model.score(X_test, y_test)
y_pred = best_model.predict(X_test)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Best Parameters:", best_params)
print("Best Score:", best_score)
print("Test Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

# Obtain predicted probabilities for the positive class
y_pred_proba = best_model.predict_proba(X_test)[:, 1]

# Calculate the False Positive Rate (FPR), True Positive Rate (TPR), and threshold values
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

# Calculate the AUC score
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()